{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# [Introduction to Text Analysis with Python](https://github.com/michellejm/NLTK_DHRI)\n",
    "### Digital Humanities Research Institute <br> June 13, 2018\n",
    "#### Michelle A. McSweeney, PhD <br> Rachel Rakov\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Concordance**: Words in their contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 1226 matches:\n",
      "s , and to teach them by what name a whale - fish is to be called in our tongue\n",
      "t which is not true .\" -- HACKLUYT \" WHALE . ... Sw . and Dan . HVAL . This ani\n",
      "ulted .\" -- WEBSTER ' S DICTIONARY \" WHALE . ... It is more immediately from th\n",
      "ISH . WAL , DUTCH . HWAL , SWEDISH . WHALE , ICELANDIC . WHALE , ENGLISH . BALE\n",
      "HWAL , SWEDISH . WHALE , ICELANDIC . WHALE , ENGLISH . BALEINE , FRENCH . BALLE\n",
      "least , take the higgledy - piggledy whale statements , however authentic , in \n",
      " dreadful gulf of this monster ' s ( whale ' s ) mouth , are immediately lost a\n",
      " patient Job .\" -- RABELAIS . \" This whale ' s liver was two cartloads .\" -- ST\n",
      " Touching that monstrous bulk of the whale or ork we have received nothing cert\n",
      " of oil will be extracted out of one whale .\" -- IBID . \" HISTORY OF LIFE AND D\n",
      "ise .\" -- KING HENRY . \" Very like a whale .\" -- HAMLET . \" Which to secure , n\n",
      "restless paine , Like as the wounded whale to shore flies thro ' the maine .\" -\n",
      ". OF SPERMA CETI AND THE SPERMA CETI WHALE . VIDE HIS V . E . \" Like Spencer ' \n",
      "t had been a sprat in the mouth of a whale .\" -- PILGRIM ' S PROGRESS . \" That \n",
      "EN ' S ANNUS MIRABILIS . \" While the whale is floating at the stern of the ship\n",
      "e ship called The Jonas - in - the - Whale . ... Some say the whale can ' t ope\n",
      " in - the - Whale . ... Some say the whale can ' t open his mouth , but that is\n",
      " masts to see whether they can see a whale , for the first discoverer has a duc\n",
      " for his pains . ... I was told of a whale taken near Shetland , that had above\n",
      "oneers told me that he caught once a whale in Spitzbergen that was white all ov\n",
      "2 , one eighty feet in length of the whale - bone kind came in , which ( as I w\n",
      "n master and kill this Sperma - ceti whale , for I could never hear of any of t\n",
      " . 1729 . \"... and the breath of the whale is frequendy attended with such an i\n",
      "ed with hoops and armed with ribs of whale .\" -- RAPE OF THE LOCK . \" If we com\n",
      "contemptible in the comparison . The whale is doubtless the largest animal in c\n"
     ]
    }
   ],
   "source": [
    "text1.concordance(\"whale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 24 of 24 matches:\n",
      " to bespeak a monument for her first love , who had been killed by a whale in \n",
      "erlasting itch for things remote . I love to sail forbidden seas , and land on\n",
      "astic our stiff prejudices grow when love once comes to bend them . For now I \n",
      "ng . Now , it was plainly a labor of love for Captain Sleet to describe , as h\n",
      "he whole , I greatly admire and even love the brave , the honest , and learned\n",
      "to - night with hearts as light , To love , as gay and fleeting As bubbles tha\n",
      "he fleece of celestial innocence and love ; and hence , by bringing together t\n",
      "s this visible world seems formed in love , the invisible spheres were formed \n",
      "tism in them , still , while for the love of it they give chase to Moby Dick ,\n",
      "own hearty good - will and brotherly love about it at all . As touching Slave \n",
      "stubborn , as malicious . He did not love Steelkilt , and Steelkilt knew it . \n",
      " of sea - usages and the instinctive love of neatness in seamen ; some of whom\n",
      "g to let that rascal beat ye ? Do ye love brandy ? A hogshead of brandy , then\n",
      "h a sog ! such a sogger ! Don ' t ye love sperm ? There goes three thousand do\n",
      "atever they may reveal of the divine love in the Son , the soft , curled , her\n",
      " come to deadly battle , and all for love . They fence with their long lower j\n",
      "de overtakes the sated Turk ; then a love of ease and virtue supplants the lov\n",
      "ove of ease and virtue supplants the love for maidens ; our Ottoman enters upo\n",
      "go , the Virgin ! that ' s our first love ; we marry and think to be happy for\n",
      "Tranquo , being gifted with a devout love for all matters of barbaric vertu , \n",
      "ght worship is defiance . To neither love nor reverence wilt thou be kind ; an\n",
      " is woe . Come in thy lowest form of love , and I will kneel and kiss thee ; b\n",
      "es , yet full of the sweet things of love and gratitude . Come ! I feel proude\n",
      "dihood of a Nantucketer ' s paternal love , had thus early sought to initiate \n"
     ]
    }
   ],
   "source": [
    "text1.concordance(\"love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Similar**: Words that appear in a similar environment as the target word\n",
    "This is determined based on concordance, so it returns words that appear in similar contexts\n",
    "\n",
    "Might do this with two different texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sea man it ship by him hand them whale view ships land me life death\n",
      "water way head nature fear\n"
     ]
    }
   ],
   "source": [
    "#How does Melville use \"love\"\n",
    "text1.similar(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "affection sister heart mother time see town life it dear elinor\n",
      "marianne me word family her him do regard head\n"
     ]
    }
   ],
   "source": [
    "#How does Austen use \"love\"\n",
    "text2.similar(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "join part hi hey and wb well ty lmao yeah hiya ok oh hello you what\n",
      "yes haha no all\n"
     ]
    }
   ],
   "source": [
    "text5.similar('lol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the next module, we need a plotting package\n",
    "\n",
    "import matplotlib as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2cdf5dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text1.dispersion_plot([\"whale\", \"monster\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Count a specific word - how many times does this sequence of characters occur in my document?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "282"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.count(\"Whale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How many **tokens** are in my text?\n",
    "\n",
    "**tokens** are unique sequences, let's start with an example:\n",
    "\n",
    "\"love\", \"bowie\", \"Bowie\", \"!\" and \":)\" are all unique **tokens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove punctuation by only capturing the items that \n",
    "#\"are alpha\" and then lowering those\n",
    "text1_tokens = []\n",
    "for t in text1:\n",
    "    if t.isalpha():\n",
    "        w=t.lower\n",
    "        text1_tokens.append(w)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218361"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First figure out how many words are in our text. \n",
    "\n",
    "len(text1_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How many **unique** words are in my text? \n",
    "\n",
    "* first make a set that groups all the \"words\" together (numbers, punctuation sequences, etc.) - this groups together **types**. \n",
    "* Token = instance\n",
    "* Type = more general (\"bowie\" and \"Bowie\" are different types - why?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209227"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set tells us how many unique items - it makes a set\n",
    "set(text1_tokens)\n",
    "len(set(text1_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-0e4a94a740c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext1_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext1_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "len(set(text1_tokens))/(len(text1_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1_slice = text1_tokens[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(text1_slice))/(len(text1_slice))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To clean our corpus, we need to:\n",
    "1. Remove capitalizaton and punctuation (DONE)\n",
    "2. Remove the stop words\n",
    "3. Lemmatize the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the stopwords from nltk.corpus\n",
    "from nltk.corpus import stopwords\n",
    "stops = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the stop words\n",
    "for t in text1_tokens:\n",
    "    if t in stops:\n",
    "        text1_tokens.remove(t)\n",
    "    else:\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(text1_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the lemmatizer function from nltk.stem \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#the lemmatizer requires that an instance be called before it is used\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DO NOT TYPE THIS CELL** <br>*This is another way to write the line above*\n",
    "\n",
    "`t1_tokens = [] \n",
    "for t in text1:\n",
    "    if t not in stops:\n",
    "        t1_tokens.append(t)\n",
    "    else:\n",
    "        pass`   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatize the words\n",
    "for t in text1_tokens:\n",
    "    wordnet_lemmatizer.lemmatize(t)\n",
    "\n",
    "len(text1_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(text1_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "I like to **sort** my **set** so I know what I have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sorted(set(text1_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now count the number of items in that set to find the number of unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "len(set(t1_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Lexical Density**: the number of unique tokens divided by the total number of words. \n",
    "\n",
    "This is a descriptive measure of language register or grade level approximations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "len(set(t1_tokens))/len(text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Frequency Distribution** is a probability object that Python deals with. We will use it to make a graph of the most common words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "my_dist = FreqDist(t1_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually nothing happens here, so check the **type** to be sure it worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "type(my_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now let's **plot** the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "my_dist.plot(50,cumulative=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It may be a little easier to look at as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "my_dist.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now let's check to see if some words we are interested in appear in our text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "love_words = ['love', 'joy', 'hope', 'amor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "my_list = []\n",
    "for word in love_words:\n",
    "    if word in t1_tokens:\n",
    "        my_list.append(word)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print(my_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's pull a book in from the Internet\n",
    "\n",
    "Project Gutenburg is a great source! www.gutenberg.org\n",
    "Let's say I'm interested in writings about East Africa from the early 20th century. I find the book, Zanzibar Tales, translated by George W. Bateman. In Project Gutenberg's database, this is text number 37472 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To make a book into a Text NLTK can deal with, we have to:\n",
    "\n",
    "* open the file from a location\n",
    "* read it/decode it \n",
    "* tokenize it (go from a string to a list of word)\n",
    "* nltk.Text() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#import the urlopen command\n",
    "from urllib.request import urlopen\n",
    "#set the url to a variable \n",
    "#DO NOT NAVIGATE TO THE SITE AND JUST COPY THE LINK - THIS IS THE TXT VERSION! BETTER TO TYPE THIS LINK\n",
    "my_url = \"https://www.gutenberg.org/files/37472/37472.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#open the file from the url\n",
    "file = urlopen(my_url)\n",
    "#read the opened file\n",
    "raw = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#specify which decoding to use. (usually utf-8)\n",
    "zt = raw.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#check the type to be sure it worked. I expect a string now.\n",
    "type(zt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#split the string into words with word_tokenize (uses spaces to distinguish words)\n",
    "zt_tokens = nltk.word_tokenize(zt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#check to make sure it worked\n",
    "type(zt_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#get an idea of how big the file is\n",
    "len(zt_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#look at the first 10 words to be sure its correct\n",
    "zt_tokens[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Yuck! That just looks like metadata! \n",
    "\n",
    "Removing metadata involves using Regular Expressions\n",
    "\n",
    "Regular Expressions are saved for another day. They are powerful but complicated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to get rid of that **intro** metadata!!\n",
    "\n",
    "I found the number **177** by copying this into Text Wrangler\n",
    "Text Wrangler counts words, characters, and spaces\n",
    "\n",
    "To do this for many files, you need Regular Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "zt_tokens[177:188]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#turn the list of words into a text nltk can recognize\n",
    "zt_text = nltk.Text(zt_tokens[177:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#check to make sure it worked\n",
    "type(zt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#get an idea of how big the file is\n",
    "len(zt_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better idea of the content of a text, it's usually best to exclude stopwords\n",
    "\n",
    "**Stopwords** perform grammatical functions, but have limited semantic content.\n",
    "\n",
    "(the, a, at, in, of, with, etc.)\n",
    "\n",
    "Two methods:\n",
    "\n",
    "* Use a pre-defined list from nltk\n",
    "* Make your own list and use a for-loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove stop words\n",
    "#mystops = stopwords.words('english')\n",
    "#zt_clean = [w for w in zt_text if w not in mystops]\n",
    "\n",
    "#while we're at it, let's finish cleaning\n",
    "zt_clean = [t.lower() for t in zt_text if t.isalpha()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#Let's check out the lexical density\n",
    "len(set(zt_clean))/len(zt_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This is the density of the whole book without the stop words, which better represents the variety of words used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "One step further! \n",
    "**Part-of-Speech Tagging**\n",
    "\n",
    "NLTK uses the Penn Tag Set. \n",
    "\n",
    "There are better options (i.e., tree tagger and polyglot), but this illustrates the idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#make a new object that has all the words and tags in it\n",
    "zt_tagged = nltk.pos_tag(zt_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(zt_tagged[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This doesn't look like a dictionary! What's going on??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "type(zt_tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We have a **list of tuples**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "I'm going to put it in a for-loop\n",
    "\n",
    "Have to deal with this in a special way \n",
    "<br>(a, b) in my_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#function to determine what is the most common tag in Zanzibar Tales\n",
    "def commontag(taggedbook):\n",
    "#create an empty dictionary\n",
    "    tag_dict = {}\n",
    "#for every word/tag combo in my list, \n",
    "    for (word, tag) in taggedbook:\n",
    "        if tag in tag_dict: \n",
    "            tag_dict[tag]+=1\n",
    "        else:\n",
    "            tag_dict[tag] = 1\n",
    "    print(tag_dict)\n",
    "\n",
    "commontag(zt_tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "I wish I would have made that return an ordered dictionary!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's add a line of code with OrderedDict in it'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def commontag(taggedbook):\n",
    "#create an empty dictionary\n",
    "    tag_dict = {}\n",
    "#for every word/tag combo in my list, \n",
    "    for (word, tag) in taggedbook:\n",
    "        if tag in tag_dict: \n",
    "            tag_dict[tag]+=1\n",
    "        else:\n",
    "            tag_dict[tag] = 1\n",
    "    tag_dict = OrderedDict(sorted(tag_dict.items(), key=lambda t: t[1]))\n",
    "    print(tag_dict)\n",
    "\n",
    "commontag(zt_tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How do you know to put all that other stuff in (i.e., sorted, lambda, etc)?!?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "*Read the docs*\n",
    "\n",
    "https://docs.python.org/3.1/whatsnew/3.1.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So far, we have counted things in our texts by looking at \n",
    "\n",
    "* Concordance\n",
    "* Words in similar environments\n",
    "* Words in common contexts\n",
    "* Unique words \n",
    "* Length of words \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Then we performed some operations, but still counted things:\n",
    "\n",
    "* Frequency Distributions\n",
    "* Lexical Density \n",
    "* Found words from a list in a text\n",
    "* Part-of-Speech Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we will perform operations on the Text itself before doing those operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#Let's check out the lexical density\n",
    "len(set(zt_clean))/len(zt_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What if I want to read in my OWN corpus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "f = open(\"/Users/mam/books/hungerGames/catchingFire.txt\", 'r')\n",
    "my_file = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "hg_tokens = nltk.word_tokenize(my_file)\n",
    "hg_tokens[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Going Forward**\n",
    "\n",
    "* Use a text editor to write complete programs\n",
    "    * Run these in the terminal\n",
    "* Use Spyder to write complete programs\n",
    "* Often save the program you write in the same file as the file you will be working with to shorted the path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do I know where to go?!?\n",
    "* http://www.nltk.org/book_1ed\n",
    "* http://www.nltk.org/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
